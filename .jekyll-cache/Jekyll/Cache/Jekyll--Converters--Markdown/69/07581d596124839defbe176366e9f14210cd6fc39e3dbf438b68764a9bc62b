I"ë-<h2 id="i-state-of-knowledge">I. State of Knowledge</h2>

<p><br /></p>

<p>For centuries, libraries have been the guardians of human knowledge. These venerable institutions collected information in print and manuscript formats and made it accessible by providing tools (e.g., card catalogues) for searching and locating information. In the past few decades, the function of these institutions has changed dramatically. The Internet has become the primary source of information. With the aid of web-based search engines, such as Google, anyone with an Internet connection can easily locate and search large amounts of textual information. Text-based information retrieval has permeated every aspect of our lives.</p>

<p>A comparable shift in the accessibility of musical information has yet to take place. Scores and audio
remain the primary means of transmitting musical information. However, neither of these forms is directly searchable. Scores can be searched once they have been converted to a computer-readable format, but the technology and resources required for the conversion are not readily available. Even if scores were widely available in a computer-readable format, we lack the tools to search them. The search problem is even more complex for audio. Despite over a decade of research in music information retrieval, the question of how to search audio files remains a difficult and, as of yet, only partially solved problem.</p>

<p>Although the computer-aided study of music information has a long history, few projects have resulted in tools and practices that can be integrated horizontally across different research programs. Until recently, little music was available in computer-searchable formats and the technology for converting images of musical scores into such a format (Optical Musical Recognition [OMR]) was not reliable enough. Additionally, the computer-aided study of music information has lacked a flagship research program, central objectives, and a view of the ‚Äúbigger picture.‚Äù</p>

<p><br /></p>

<h2 id="ii-innovation-and-complementarity-in-the-research-axes">II. Innovation and Complementarity in the Research Axes</h2>

<p><br /></p>

<p>There are two main research axes in this program: <strong>Content</strong> and <strong>Searching &amp; Analysis</strong>. The Content axis collects and organizes music-related documents in various formats (e.g., scores, audio, and biographical information about composers) so that users can find what they are looking for easily and efficiently. It encompasses projects concerning the improvement of OMR technology (Burgoyne et al. 2009, 2008, 2007a; Charalampos et al. 2014; Fujinaga 2004; Hankinson 2014; Hankinson et al. 2012a, 2010), metadata management (Angeles et al. 2010), biographical data acquisition (prosopography) (Fujinaga 2014, Weiss et al. 2010), and audio feature extraction (McKay et al. 2006a; McEnnis et al. 2006a). Until now, the only OMR technology available was proprietary ‚Äúblack box‚Äù software that cannot be improved or adjusted for different types of notation. Our OMR software is open-source and can be trained to work on different types of notation.</p>

<p>The Searching &amp; Analysis axis creates tools and techniques for searching and analyzing the information collected from the Content axis. From audio sources, we are creating tools for automatic genre classification (McKay et al. 2010b, 2009a, 2009b, 2006c, 2005a, 2005b, 2005c, 2004), harmonic analysis (Burgoyne et al. 2013, 2011, 2007b), performance analysis (Devaney et al. 2011a, 2011b, 2011c), and timbre recognition (Fujinaga et al. 2000). From scores in symbolic notation we are developing tools for searching and analyzing melody, harmony, counterpoint, and structure (Cumming et al. 2015a; Fujinaga et al. 2013). From text documents about music we are developing ways to link data that will reveal new connections among musicians, composers, patrons, places, and institutions.</p>

<p>Both axes examine how users interact with digital music and continually improve the tools we have developed (Hankinson et al. 2012b, 2012c, 2009, Burlet et al. 2012). Figure 1 shows the overall structure with examples of research projects under each axis.</p>

<p><img src="http://localhost:4000/assets/img/Structure_of_MIRAI.png" alt="" /></p>

<p><br /></p>

<p>The two research axes are independent but complementary. Content that is not searchable in intelligent ways is not useful. Search and analysis algorithms require content to work on. Work can proceed on the two axes independently, but ultimately it is the combination that makes our research program valuable. The ‚ÄúUser Interface‚Äù box in Figure 1 points to a feature of our program that applies to both axes: tools that are easy to use have the potential for broad impact. With our complementary research axes, the MIRAI team is building efficient and user-friendly tools to accommodate large-scale distributed processing. With these tools, libraries and archives anywhere in the world will be able to process their music collections and make them available to wider audiences for study, performance, and appreciation.</p>

<p><br /></p>

<h2 id="iii-the-mirai-team">III. The MIRAI Team</h2>

<p><br /></p>

<p>We are a <a href="https://miraiqc.ca/people/">diverse team</a> dedicated to accomplishing this mission. MIRAI includes music scholars, performers, librarians, and music technologists, working to create new tools for research and analysis of the collections of our partner museums, research libraries, and universities. Document processing and OMR correction for this collection will be carried out by musicians, students, and scholars around the world.</p>

<p><br /></p>

<p><br /></p>

<hr />

<p><br /></p>

<p><br /></p>

<h2 id="i-√©tat-des-connaissances">I. √âtat des Connaissances</h2>

<p><br /></p>

<p>Pendant des si√®cles, les biblioth√®ques ont √©t√© les gardiennes du savoir humain. Ces institutions v√©n√©rables ont longtemps collect√© des documents sous forme imprim√©es ou manuscrites, et ont permis l‚Äôacc√®s √† leurs informations gr√¢ce √† des outils adapt√©s √† leur exploration et √† leur localisation tels, par exemple, que les cartes de catalogue. Au cours des derni√®res d√©cennies, la fonction de ces institutions a drastiquement chang√©, Internet √©tant devenu le principal pourvoyeur d‚Äôinformation. En effet, √† l‚Äôaide de moteurs de recherche tels que Google, toute personne √©quip√©e d‚Äôune connexion √† Internet peut ais√©ment localiser et explorer de grandes quantit√©s d‚Äôinformations textuelles au point que ce type de recherche est pr√©sent dans tous les aspects de notre vie.</p>

<p>Cependant, un tel changement ne s‚Äôest pas encore op√©r√© pour les informations musicales. M√™me si les partitions et les documents audio restent les principaux moyens de transmission, aucun de ces formats ne peut √™tre directement explor√©. La technologie et les ressources n√©cessaires √† la conversion de partitions en un format lisible par l‚Äôordinateur sont difficiles √† se procurer, et m√™me lorsque cela est possible, les outils de recherches n‚Äôexistent pas. Le probl√®me est encore plus complexe lorsque le document est sous format audio. Malgr√© plus de dix ans de recherches, l‚Äôexploration de ces documents reste un probl√®me difficile √† r√©soudre.</p>

<p>Bien que l‚Äô√©tude de la musique √† l‚Äôaide des ordinateurs ait une longue histoire, peu de projets ont d√©bouch√© sur des outils ou des pratiques int√©grables horizontalement √† travers diff√©rents programmes de recherche. Jusque r√©cemment, les documents directement disponibles en un format permettant l‚Äôexploration par ordinateur √©taient tr√®s rares. De plus, la technologie pour convertir l‚Äôimage d‚Äôune partition en un tel format n‚Äô√©tait pas fiable (Reconnaissance Optique de la Musique [ROM]). Enfin, les √©tudes portant sur l‚Äôinformation musicale ont manqu√© jusque l√† d‚Äôun p√¥le de recherche, d‚Äôobjectifs pr√©cis et d‚Äôune vue d‚Äôensemble.</p>

<p><br /></p>

<h2 id="ii-originalit√©-et-compl√©mentarit√©-des-axes-de-recherches">II. Originalit√© et Compl√©mentarit√© des Axes de Recherches</h2>

<p><br /></p>

<p>Il y a deux principaux axes de recherche dans ce programme: <strong>Contenu</strong> et <strong>Recherche et Analyse</strong>. Le premier axe (<strong>Contenu</strong>) collecte et organise les documents musicaux en divers formats que les utilisateurs peuvent parcourir facilement et efficacement (partitions, audio, informations biographiques, etc.). Il couvre les projets portant sur l‚Äôam√©lioration de la technologie ROM (Burgoyne et al. 2009, 2008, 2007a; Charalampos et al. 2014; Fujinaga 2004; Hankinson 2014; Hankinson et al. 2012a, 2010), sur la gestion des m√©tadonn√©es (Angeles et al. 2010), sur l‚Äôacquisition des donn√©es biographiques, ou prosopographie (Fujinaga 2014, Weiss et al. 2010), et l‚Äôextraction de donn√©es audio (McKay et al. 2006a; McEnnis et al. 2006a). Jusqu‚Äô√† pr√©sent, la seule technologie ROM disponible √©tait un logiciel-propri√©taire en ‚Äúboite noire‚Äù qu‚Äôil n‚Äô√©tait possible ni d‚Äôam√©liorer ni d‚Äôadapter √† diff√©rent types de notation. Notre logiciel OMR est libre d‚Äôacc√®s et peut √™tre entra√Æn√© pour de telles situations.</p>

<p>Le second axe (<strong>Recherche et Analyse</strong>) porte sur le d√©veloppement d‚Äôoutils et de techniques destin√©s √† la recherche et √† l‚Äôanalyse des informations r√©unies par le premier axe (<strong>Contenu</strong>). √Ä partir de documents audio, nous cr√©ons des outils de classification automatique de genres musicaux (McKay et al. 2010b, 2009a, 2009b, 2006c, 2005a, 2005b, 2005c, 2004), d‚Äôanalyse harmonique (Burgoyne et al. 2013, 2011, 2007b), d‚Äôanalyse de l‚Äôinterpr√©tation (Devaney et al. 2011a, 2011b, 2011c), et de reconnaissance des timbres instrumentaux (Fujinaga et al. 2000). √Ä partir de partitions en notation symbolique, nous d√©veloppons des outils capables d‚Äôexplorer et d‚Äôanalyser la m√©lodie, l‚Äôharmonie, le contrepoint et la structure de la musique (Cumming et al. 2015a; Fujinaga et al. 2013). Enfin, √† partir des documents textuels sur la musique, nous relions entre elles des donn√©es qui √©clairent d‚Äôun jour nouveau les interactions entre musiciens, compositeurs, m√©c√®nes, lieux de concerts et institutions.</p>

<p>Ces deux axes examinent la fa√ßon dont les utilisateurs interagissent avec la musique digitale et am√©liorent continuellement les outils d√©velopp√©s jusqu‚Äôici (Hankinson et al. 2012b, 2012c, 2009, Burlet et al. 2012). La Figure 1 en illustre la structure globale avec divers exemples de projets de recherche. Ils sont ind√©pendants mais compl√©mentaires: un contenu que l‚Äôon ne peut explorer de mani√®re intelligente est inutile ; et les algorithmes de recherche et d‚Äôanalyse ne fonctionnent que s‚Äôils ont un contenu bien ordonn√© sur lequel s‚Äôex√©cuter. Il est possible de travailler ind√©pendamment sur chacun d‚Äôentre eux, mais c‚Äôest leur combinaison qui donne √† notre programme de recherche toute sa valeur. La bo√Æte ‚ÄúInterface utilisateur‚Äù de la Figure 1 en est un exemple : les outils faciles d‚Äôutilisation ont une port√©e plus large.</p>

<p>Gr√¢ce √† la compl√©mentarit√© de nos deux axes de recherche, l‚Äô√©quipe de MIRI met au point des outils efficaces et d√©velopp√©s pour l‚Äôutilisateur, qui facilitent les recherches de grande envergure. Ils permettront aux biblioth√®ques et archives du monde entier de traiter leurs collections musicales et d‚Äôen faciliter l‚Äôacc√®s au public d√©sireux de les √©tudier, de les jouer et de les appr√©cier.</p>

<p><br /></p>

<p><br /></p>
:ET